{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Marko and Maximus Hackathon Solution\n",
    "# 2/20/25\n",
    "\n",
    "# Program flow:\n",
    "# Imports (software)\n",
    "# Imports (data)\n",
    "# Confirm data properly imported\n",
    "# Fix bad data values, if applicable\n",
    "# Load training and testing data\n",
    "# Fitting the model\n",
    "# Checking the model validation\n",
    "# Testing the model\n",
    "# Testing whether the model is accurate on a scatter graph\n",
    "# Permutations!\n",
    "# Partial dependence plots\n",
    "# The actual neural network training\n",
    "# Everything else\n",
    "# \n",
    "# \n",
    "# Note: Training data MUST be kept separately from testing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all requirements\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plotter\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "\n",
    "# Pull in imports from SciKit Learn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import root_mean_squared_error, make_scorer\n",
    "\n",
    "# copied over from apca.ipynb\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Showing test data...\n",
      "\n",
      "\n",
      "---Showing training data---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import training data and testing data,\n",
    "# and confirm it was successfully imported\n",
    "# todo: get rid of the absolute filepaths and use relative filepaths... like yesterday\n",
    "# todo [2]: move the ipynb file out of the archive folder and in the main project directory?\n",
    "\n",
    "def import_data(type, uri, delim):\n",
    "    pass\n",
    "\n",
    "test_data = pd.read_csv(r\"C:\\Users\\vucinm\\Desktop\\college\\spring-2025\\psyc-4961\\MARP-Project\\test_data.csv\", delimiter=\";\")\n",
    "train_data = pd.read_csv(r\"C:\\Users\\vucinm\\Desktop\\college\\spring-2025\\psyc-4961\\MARP-Project\\train_data.csv\", delimiter=\";\")\n",
    "\n",
    "if test_data is None or train_data is None:\n",
    "    # basic integrity check (because a few times it didn't work)\n",
    "    print('Could not import test or training data : try again')\n",
    "\n",
    "print('\\n----Showing test data...\\n')\n",
    "test_data.head() # integrity check\n",
    "print('\\n---Showing training data---\\n')\n",
    "#train_data.head() # integrity check (moved to next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject    country     rel_1     rel_2  rel_3  rel_4     rel_5     rel_6  \\\n",
      "0     5362    Ireland  0.833333  0.857143    1.0      1  0.833333  0.833333   \n",
      "1    10070         UK  0.000000  0.000000    0.0      0  0.166667  0.166667   \n",
      "2     9515     Turkey  0.000000  0.000000    0.5      0  0.000000  0.500000   \n",
      "3     5960     Israel  0.500000  0.428571    0.5      0  0.166667  0.500000   \n",
      "4     6935  Lithuania  0.000000  0.000000    0.5      1  0.166667  0.666667   \n",
      "\n",
      "      rel_7  rel_8  ...  gender  ses  education            ethnicity  \\\n",
      "0  1.000000   1.00  ...   woman  6.0          4   Caucasian/European   \n",
      "1  0.166667   0.00  ...   woman  5.0          3   Caucasian/European   \n",
      "2  0.000000   0.00  ...     man  6.0          5  Middle-Eastern/Arab   \n",
      "3  0.666667   0.25  ...   woman  7.0          4        Mixed / other   \n",
      "4  0.166667   0.00  ...   woman  7.0          3   Caucasian/European   \n",
      "\n",
      "                 denomination           gdp  gdp_scaled   sample_type  \\\n",
      "0  Christian (Roman Catholic)  78806.431996    1.973267  online panel   \n",
      "1                         NaN  42491.364435    0.332479  online panel   \n",
      "2                         NaN   9311.366117   -1.166661  online panel   \n",
      "3                         NaN  41613.998082    0.292837      students   \n",
      "4  Christian (Roman Catholic)  19089.707506   -0.724855      students   \n",
      "\n",
      "      compensation  attention_check  \n",
      "0  monetary reward                1  \n",
      "1  monetary reward                1  \n",
      "2  monetary reward                1  \n",
      "3    course credit                1  \n",
      "4  no compensation                1  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject    country     rel_1     rel_2  rel_3  rel_4     rel_5     rel_6  \\\n",
      "0     4079    Germany  0.000000  0.000000    0.0      0  0.166667  0.166667   \n",
      "1     1301     Canada  0.000000  0.142857    0.0      0  0.500000  0.166667   \n",
      "2     2689    Denmark  0.833333  0.714286    1.0      1  0.666667  1.000000   \n",
      "3     5909     Israel  0.000000  0.000000    0.0      0  0.166667  0.000000   \n",
      "4       51  Australia  1.000000  1.000000    1.0      1  0.833333  1.000000   \n",
      "\n",
      "      rel_7  rel_8  ...  gender  ses  education           ethnicity  \\\n",
      "0  0.166667   0.00  ...   woman  7.0          5  Caucasian/European   \n",
      "1  0.166667   0.00  ...   woman  6.0          4  Caucasian/European   \n",
      "2  0.666667   0.50  ...     man  6.0          4             African   \n",
      "3  0.000000   0.00  ...     man  7.0          4       Mixed / other   \n",
      "4  1.000000   0.75  ...     man  9.0          7  Caucasian/European   \n",
      "\n",
      "  denomination           gdp  gdp_scaled   sample_type     compensation  \\\n",
      "0          NaN  48195.579904    0.590207         mixed           raffle   \n",
      "1          NaN  46210.547623    0.500519  online panel  monetary reward   \n",
      "2       Muslim  60726.466535    1.156377         mixed           raffle   \n",
      "3          NaN  41613.998082    0.292837      students    course credit   \n",
      "4       Muslim  57305.299016    1.001802  online panel  monetary reward   \n",
      "\n",
      "   attention_check  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we would confirm that the data is properly imported.\n",
    "# So this is the bit where we would confirm that there are no missing or incorrect values like NaN\n",
    "# If there are, this is where we would fix them.\n",
    "\n",
    "def fix_bad_data_values():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we begin to load the data which will eventually be used to train the models.\n",
    "# We want a training variable and test variable for both the X and Y values.\n",
    "# (in keeping with formatting, X should be uppercase and y should be lowercase both times)\n",
    "\n",
    "def load_data():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model to the baseline training _and_ testing data (so 2 different models)\n",
    "\n",
    "def fit_training_model():\n",
    "    pass\n",
    "\n",
    "def fit_testing_model():\n",
    "    pass\n",
    "\n",
    "lin_mod_train = LinearRegression()\n",
    "lin_mod_test = LinearRegression()\n",
    "# lin_mod_train.fit(X_train, y_train)\n",
    "# lin_mod_test.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check that the code is working out properly here, \n",
    "# we do a simple visual test.\n",
    "\n",
    "def simple_vis_test():\n",
    "    pass\n",
    "\n",
    "# Refer to explainable_deep_learning_1.ipynb, cell 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next up is permutations and permutation importance - determine them.\n",
    "# One method per cell - clean code hygiene\n",
    "def find_permutations():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find permutation importance\n",
    "def find_permutation_importance():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial dependence plot\n",
    "# This is just a wrapper for shap's partial dependence plot function\n",
    "def make_partial_dependence_plot():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we actually have to train the neural network!\n",
    "# We break this process up into several cells.\n",
    "\n",
    "# First, we create the network.\n",
    "# And check it was actually created.\n",
    "\n",
    "def make_neural_network():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we train the network on the training data.\n",
    "\n",
    "def train_neutral_network():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we evaluate the network on the test set.\n",
    "def test_neural_network():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we compute the permutation importances \n",
    "# (both manually and with SciKit Learn)\n",
    "# This is where we break our own rules of \"one method per cell\"\n",
    "# because both methods are super similar.\n",
    "\n",
    "def compute_permutation_importances():\n",
    "    pass\n",
    "\n",
    "def autocompute_permutation_importances():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavioral-data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
